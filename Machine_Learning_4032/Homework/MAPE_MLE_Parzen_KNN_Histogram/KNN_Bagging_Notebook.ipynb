{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this task, you will analyze a dataset containing employee information to train predictive models that determine whether employees have left the company (attrited) or not. The process will begin with an in-depth exploration of the dataset, followed by a thorough analysis of its features and the implementation of essential preprocessing techniques, such as label encoding and feature scaling. Subsequently, you will construct and assess models using K-Nearest Neighbors (KNN), Random Forest and Bagging. After training and optimizing each model, you will evaluate their performance by comparing metrics such as accuracy and feature importance, in order to identify the most effective approach for accurate attrition prediction."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "student_number = None\n",
    "full_name = None\n",
    "assert student_number and full_name is not None, 'please input your information'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure visualizations\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxij84ZZMICb"
   },
   "source": [
    "# Load and Explore Dataset (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Note: \"Attrition\" is our target column\n",
    "\n",
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.head(5)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKtCXW57PS-k"
   },
   "outputs": [],
   "source": [
    "# TODO: Check the basic structure of the dataset using .info() and .describe()\n",
    "# Use: df.info() to check data types and missing values\n",
    "# Use: df.describe() to get summary statistics of numeric features\n",
    "\n",
    "# TODO: Check for any missing values in the dataset\n",
    "# Use: df.isnull().sum() to find if any column has missing values\n",
    "\n",
    "# TODO: Explore the target variable (binary classification)\n",
    "# Use value_counts() to see the distribution of our target (Attrition) column and then visualize it (bar plot).\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Examine the DataFrame to gain insights into individuals' monthly income and the factors that typically influence this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot (line plot) the average MonthlyIncome against the YearsAtCompany. \n",
    "# TODO: Then find which departments have the highest and lowest incomes on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nViqoo1oMNPN"
   },
   "source": [
    "# Data Preprocessing (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encode categorical columns and create a new DataFrame. Then split this data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Label encode all categorical columns\n",
    "encoded_df= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joQQVv4TPTXY"
   },
   "outputs": [],
   "source": [
    "# Split into features and target variable\n",
    "X = df.drop(columns=['Attrition'])\n",
    "y = df['Attrition']\n",
    "\n",
    "# TODO: Perform a train-test split using train_test_split() from sklearn\n",
    "# Split the dataset into training and test sets with a test size of 30%\n",
    "\n",
    "# TODO: Scale the features using StandardScaler\n",
    "# Fit the scaler on the training data and transform both the training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WoDFp4Y8MR2H"
   },
   "source": [
    "# K-Nearest Neighbors (KNN) Model (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class CustomKNN:\n",
    "    def __init__(self, k):\n",
    "        \"\"\"\n",
    "        Initialize the KNN classifier.\n",
    "\n",
    "        Parameters:\n",
    "        - k (int): Number of neighbors to consider.\n",
    "        \"\"\"\n",
    "        # Store the number of neighbors (k)\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit the KNN classifier to the training data.\n",
    "\n",
    "        Parameters:\n",
    "        - X_train (numpy array): Training feature vectors.\n",
    "        - y_train (numpy array): Training labels.\n",
    "        \"\"\"\n",
    "        # Store training data\n",
    "        self.X_train = np.array(X_train)\n",
    "        self.y_train = np.array(y_train)\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Calculate the Euclidean distance between two data points.\n",
    "\n",
    "        Parameters:\n",
    "        - x1 (numpy array): First data point.\n",
    "        - x2 (numpy array): Second data point.\n",
    "\n",
    "        Returns:\n",
    "        - float: Euclidean distance between x1 and x2.\n",
    "        \"\"\"\n",
    "        # TODO: Calculate and return the Euclidean distance\n",
    "        pass\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict labels for test data.\n",
    "\n",
    "        Parameters:\n",
    "        - X_test (numpy array): Test feature vectors.\n",
    "\n",
    "        Returns:\n",
    "        - numpy array: Predicted labels.\n",
    "        \"\"\"\n",
    "        # TODO: Predict label for each test instance and return the array of predictions\n",
    "        pass\n",
    "\n",
    "    def _predict(self, x):\n",
    "        \"\"\"\n",
    "        Predict label for a single data point.\n",
    "\n",
    "        Parameters:\n",
    "        - x (numpy array): Test data point.\n",
    "\n",
    "        Returns:\n",
    "        - int: Predicted label.\n",
    "        \"\"\"\n",
    "        # TODO: Compute distances from x to all training points.\n",
    "        # Find the indices and labels of k nearest neighbors.\n",
    "        # Perform majority vote and return the most common label among them.\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can choose any range of k values that you want.\n",
    "k_values = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "accuracies = []\n",
    "\n",
    "\n",
    "\n",
    "for k in k_values:\n",
    "    y_pred_custom= []\n",
    "    \n",
    "    # TODO: Fit the model using the scaled training data\n",
    "    # TODO: Make predictions on the scaled test data\n",
    "    # TODO: Evaluate the model's accuracy for each value of k and choose the best one\n",
    "    \n",
    "    print(f'k: {k} - Accuracy: {accuracy_score(y_test, y_pred_custom)}')\n",
    "    \n",
    "\n",
    "Best_custom_model= None\n",
    "\n",
    "# Keep the best_k value (needed later on with bagging)\n",
    "best_k= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jbb7yn8QPTt0"
   },
   "outputs": [],
   "source": "# TODO: Print the accuracy and classification report using Scikit-learn metrics for your best model\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVEF9tO2PUEb"
   },
   "outputs": [],
   "source": [
    "# TODO: Create a confusion matrix for KNN predictions\n",
    "# Use confusion_matrix from sklearn.metrics\n",
    "\n",
    "# TODO: Visualize the confusion matrix using seaborn's heatmap\n",
    "# Add annotations and a title for better readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation (5 points)\n",
    "In this section, you will assess your model's performance on a new set of unseen data. Load the test.csv file (which has already been encoded), use your best_custom_model to make predictions, and save the results in a DataFrame named 'result.csv'. The DataFrame should contain a column labeled 'target', which holds your model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test.csv\n",
    "eval_df= pd.read_csv('test.csv')\n",
    "\n",
    "# TODO: Use your old scaler to scale the data\n",
    "# TODO: Predict using your model\n",
    "\n",
    "y_pred_eval= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results as a csv file\n",
    "result_df= pd.DataFrame()\n",
    "result_df['target']=pd.Series(y_pred_eval)\n",
    "result_df.to_csv('result.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2tDZYAuMk5l"
   },
   "source": [
    "# Bagging with KNN (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ie5KQ50dPVQY"
   },
   "source": [
    "# TODO: Implement Bagging with KNN\n",
    "# Use BaggingClassifier with KNeighborsClassifier as the base estimator\n",
    "# Here we use the best_k value we found before\n",
    "\n",
    "bagging_knn = BaggingClassifier(KNeighborsClassifier(n_neighbors=best_k), n_estimators=50, random_state=42)\n",
    "\n",
    "# TODO: Fit the BaggingClassifier on the scaled training data\n",
    "# Use bagging_knn.fit() with the training data\n",
    "\n",
    "# TODO: Use the trained Bagging model for predictions on the test data\n",
    "# Use bagging_knn.predict()\n",
    "\n",
    "# TODO: Print the Bagging KNN model accuracy and classification report\n",
    "# Use accuracy_score and classification_report"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_2_fnxpaPVps",
    "ExecuteTime": {
     "end_time": "2025-03-12T15:28:23.248108Z",
     "start_time": "2025-03-12T15:28:23.248108Z"
    }
   },
   "source": [
    "# TODO: Create a confusion matrix for Bagging KNN predictions\n",
    "# Use confusion_matrix from sklearn.metrics\n",
    "\n",
    "# TODO: Visualize the confusion matrix using seaborn's heatmap\n",
    "# Add annotations and a title for better readability"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORGr2kDzM3FS"
   },
   "source": [
    "# Model Comparison (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3o7CNF7PXFY"
   },
   "outputs": [],
   "source": [
    "# TODO: Compare model accuracies for KNN, Bagging KNN\n",
    "# Create a DataFrame with model names and their respective accuracies\n",
    "\n",
    "# TODO: Visualize the model comparison using a line plot\n",
    "# Use seaborn's line plot to plot model names vs. accuracies"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
